# Konsultacje

## Pytania
* Jaki format zapytań do API
  * brakujące wartości
* Jak mamy zbierać logi
* Na czym ma polegać analiza eksperymentu A/B
* Materiały pokazujące, że implementacja działa - testy?
* Atrybuty takie jak `avg_rating_by_host` (globalne statystyki)
* Zmiana kryteriów sukcesu
* Poprawki do etapu 1

## Notatka
* Zmiana kryterium sukcesu
  * ok, mamy zgodę
* Brakujące wartości
  * wszystkie które miały brakujące wartości w zbiorze
* Przypisanie do eksperymentu
  * id użytkownika może być
  * ale można równie dobrze zrobić po np. id listingu
* Jakie dane do analizy
  * zasymulujemy na podstawie zbioru testowego
  * porównujemy do avg_rating ze zbioru testowego
* Materiały pokazujące, że implementacja działa
  * powinien być skrypt wykonujący eksperyment A/B - symulujący requesty
  * może być przykład curla w README
* Dostęp do bazy operacyjnej
  * chcemy, żeby dobre atrybuty (avg_rating_by_host) były podawane na wejście
  * np. jakby inny mikroserwis wołał nasz mikroserwis
  * zakładamy, że avg_rating_by_host będzie opcjonalnym wejściem
* Normalizacja danych
  * problem, jeśli zmieni się rozkład w danych (zmiany procesu biznesowego)
  * normalizacja powinna być robiona tak jak robimy - takie skalowanie jak na zbiorze treningowym
